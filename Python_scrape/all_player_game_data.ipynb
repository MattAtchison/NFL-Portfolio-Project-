{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# set up webdriver with headless mode\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # Enable headless mode\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up webDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# go to the ESPN NFL scoreboard page\n",
    "driver.get(\"https://www.espn.com/nfl/scoreboard\")\n",
    "time.sleep(5)  # Allow page to load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wait = WebDriverWait(driver, 10)  # Define wait here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start webdriver \n",
    "wait = WebDriverWait(driver, 15)  \n",
    "\n",
    "all_links = []\n",
    "\n",
    "while True:\n",
    "    # ising javascript \n",
    "    elements = driver.execute_script(\n",
    "        \"return [...document.querySelectorAll('.Arrow.flex.justify-center.items-center.Arrow--left')]\"\n",
    "    )\n",
    "\n",
    "    # check if any elements were found\n",
    "    if not elements:\n",
    "        print(\"No elements found.\")\n",
    "        break\n",
    "\n",
    "    # get the href using javascript \n",
    "    week_js1 = driver.execute_script(\n",
    "        \"return [...document.querySelectorAll('div.Week.currentWeek div.Week__wrapper div.custom--week a')].map(e => e.href);\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # filter links with season 2 in it \n",
    "    filtered_links = [link for link in week_js1 if \"/seasontype/2\" in link]\n",
    "    \n",
    "    # add the extracted links to the list\n",
    "    # convert to set to automatically remove duplicates\n",
    "    all_links = list(set(all_links + filtered_links))   \n",
    "\n",
    "    # Use javascript to check if the button is disabled\n",
    "    is_disabled = driver.execute_script(\n",
    "        \"\"\"\n",
    "        return document.querySelector('.Arrow.flex.justify-center.items-center.Arrow--left').classList.contains('disabled');\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # if the button is disabled, stop the loop\n",
    "    if is_disabled:\n",
    "        print(\"Reached the beginning of the carousel. Stopping.\")\n",
    "        break\n",
    "\n",
    "    # click the first element in the list to go to the previous carousel page\n",
    "    elements[0].click()\n",
    "\n",
    "# Print all the collected links after the loop finishes\n",
    "print(\"All links collected:\")\n",
    "for link in all_links:\n",
    "    print(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list to store boxscore links\n",
    "boxscore_links = []\n",
    "\n",
    "\n",
    "# loop through each week link\n",
    "for link in all_links:\n",
    "    try:\n",
    "        print(f\"\\nNavigating to: {link}\")\n",
    "        driver.get(link)  # Open the page in the browser\n",
    "\n",
    "        # Wait for the page to fully load\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"fittPageContainer\")))\n",
    "\n",
    "\n",
    "        # Extract the week number from the URL\n",
    "        week_number = link.split(\"/week/\")[1].split(\"/\")[0]  # Extracts the \"18\" from \"/week/18/\"\n",
    "\n",
    "        # Extract boxscore links\n",
    "        boxscores = driver.find_elements(By.XPATH, '//a[contains(@href, \"/boxscore/\")]')\n",
    "\n",
    "        for item in boxscores:\n",
    "            boxscore = item.get_attribute('href')\n",
    "            if boxscore and '/boxscore/' in boxscore:\n",
    "                boxscore_links.append(boxscore)  # Append only the link (no dictionary)\n",
    "                print(f\"Found boxscore link: {boxscore}\")\n",
    "\n",
    "        # Stop after processing one week\n",
    "        # weeks_processed += 1\n",
    "        if weeks_processed >= max_weeks_to_process:\n",
    "            break  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {link}: {e}\")\n",
    "\n",
    "# Print collected boxscore links\n",
    "print(\"\\nAll boxscore links collected:\")\n",
    "for link in boxscore_links:\n",
    "    game_ids = [link.split(\"gameId/\")[-1] for link in boxscore_links]\n",
    "    print(game_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n",
    "# I need to restrucue this into three tables then union it \n",
    "# passing, rushing, receving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "from tqdm import tqdm  # for progress bar (install with pip install tqdm)\n",
    "\n",
    "# MySQL Database Credentials\n",
    "DB_USER = \"root\"\n",
    "DB_PASSWORD = \"_Joseph344\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_NAME = \"NFL_Project2\"\n",
    "\n",
    "engine = create_engine(f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}\")\n",
    "\n",
    "def get_player_stats(game_id, retries=3):\n",
    "    \"\"\"Fetches player stats and exports offense and defense data to MySQL.\"\"\"\n",
    "    url = f\"https://site.api.espn.com/apis/site/v2/sports/football/nfl/summary?event={game_id}\"\n",
    "    scoreboard_url = f\"https://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard/{game_id}\"\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            # Add delay between requests to avoid rate limiting\n",
    "            time.sleep(0.5)  \n",
    "            \n",
    "            response = requests.get(url, timeout=10)\n",
    "            s_response = requests.get(scoreboard_url, timeout=10)\n",
    "\n",
    "            response.raise_for_status()\n",
    "            s_response.raise_for_status()\n",
    "\n",
    "            score = s_response.json()\n",
    "            data = response.json()\n",
    "\n",
    "            season_type = score.get(\"season\", {}).get(\"slug\", \"na\")\n",
    "            players_data = data.get(\"boxscore\", {}).get(\"players\", [])\n",
    "            \n",
    "            all_offense = []\n",
    "            all_defense = []\n",
    "            week = data.get(\"header\", {}).get(\"week\", \"na\")\n",
    "\n",
    "            for team in players_data:\n",
    "                team_name = team.get(\"team\", {}).get(\"displayName\", \"Unknown Team\")\n",
    "                team_id = team.get(\"team\", {}).get(\"id\", \"na\")\n",
    "                \n",
    "                for stat_group in team.get(\"statistics\", []):\n",
    "                    stat_type = stat_group.get(\"name\", \"Unknown Stats\")\n",
    "                    labels = stat_group.get(\"keys\", [])\n",
    "                    \n",
    "                    for player in stat_group.get(\"athletes\", []):\n",
    "                        player_name = player.get(\"athlete\", {}).get(\"displayName\", \"Unknown Player\")\n",
    "                        player_id = player.get(\"athlete\", {}).get(\"id\", \"Unknown ID\")\n",
    "                        stats = player.get(\"stats\", [])\n",
    "                        \n",
    "                        player_stats = {\n",
    "                            \"Player_ID\": player_id,\n",
    "                            \"Game_ID\": game_id,\n",
    "                            \"Team\": team_name,\n",
    "                            \"season_type\": season_type,  \n",
    "                            \"Player\": player_name,\n",
    "                            \"Team_Id\": team_id,\n",
    "                            \"Week\": week\n",
    "                        }\n",
    "                        player_stats.update(dict(zip(labels, stats)))\n",
    "                        \n",
    "                        if stat_type.lower() in [\"passing\", \"rushing\", \"receiving\"]:\n",
    "                            all_offense.append(player_stats)\n",
    "                        elif stat_type.lower() == \"defensive\":\n",
    "                            all_defense.append(player_stats)\n",
    "\n",
    "            # Convert to pandas DataFrames\n",
    "            df_offense = pd.DataFrame(all_offense) if all_offense else pd.DataFrame()\n",
    "            df_defense = pd.DataFrame(all_defense) if all_defense else pd.DataFrame()\n",
    "\n",
    "            # Export to MySQL\n",
    "            if not df_offense.empty:\n",
    "                df_offense.to_sql(\"offense_stats\", con=engine, if_exists=\"append\", index=False)\n",
    "                print(f\"Offensive stats for Game ID {game_id} inserted into MySQL ✅\")\n",
    "            \n",
    "            if not df_defense.empty:\n",
    "                df_defense.to_sql(\"defense_stats\", con=engine, if_exists=\"append\", index=False)\n",
    "                print(f\"Defensive stats for Game ID {game_id} inserted into MySQL ✅\")\n",
    "            \n",
    "            # If successful, break out of retry loop\n",
    "            break\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for Game ID {game_id}: {e}\")\n",
    "            if attempt == retries - 1:\n",
    "                print(f\"Failed to process Game ID {game_id} after {retries} attempts\")\n",
    "            time.sleep(2)  # Wait longer between retries\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error processing Game ID {game_id}: {e}\")\n",
    "            break\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # Extract game IDs from boxscore_links\n",
    "    game_ids = [link.split(\"gameId/\")[-1] for link in boxscore_links]\n",
    "\n",
    "    \n",
    "    # Process each game ID with progress bar\n",
    "    for game_id in tqdm(game_ids, desc=\"Processing Games\"):\n",
    "        print(f\"\\nProcessing Game ID: {game_id}\")\n",
    "        get_player_stats(game_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
