{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",    \n",
    "    user=\"root\",          \n",
    "    password=\"_Joseph344\", \n",
    "    database=\"NFL_Project2\" \n",
    ")\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up webdriver \n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# navigate to the ESPN NFL scoreboard page\n",
    "driver.get(\"https://www.espn.com/nfl/scoreboard\")\n",
    "time.sleep(5)  # Allow page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriverWait\n",
    "wait = WebDriverWait(driver, 15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start webdriver \n",
    "wait = WebDriverWait(driver, 15)  \n",
    "\n",
    "all_links = []\n",
    "\n",
    "while True:\n",
    "    # Use javascript to get all elements \n",
    "    elements = driver.execute_script(\n",
    "        \"return [...document.querySelectorAll('.Arrow.flex.justify-center.items-center.Arrow--left')]\"\n",
    "    )\n",
    "\n",
    "    # check if any elements were found\n",
    "    if not elements:\n",
    "        print(\"No elements found.\")\n",
    "        break\n",
    "\n",
    "    # get the href attributes using javascript\n",
    "    week_js1 = driver.execute_script(\n",
    "        \"return [...document.querySelectorAll('div.Week.currentWeek div.Week__wrapper div.custom--week a')].map(e => e.href);\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # filter for only links containing '/season/2'\n",
    "    filtered_links = [link for link in week_js1 if \"/seasontype/2\" in link]\n",
    "    \n",
    "    # add the extracted links to the list\n",
    "    all_links.extend(filtered_links)\n",
    "\n",
    "    # use javascript to check if the button is disabled\n",
    "    is_disabled = driver.execute_script(\n",
    "        \"\"\"\n",
    "        return document.querySelector('.Arrow.flex.justify-center.items-center.Arrow--left').classList.contains('disabled');\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # if the button is disabled, stop the loop\n",
    "    if is_disabled:\n",
    "        print(\"Reached the beginning of the carousel. Stopping.\")\n",
    "        break\n",
    "\n",
    "\n",
    "    elements[0].click()\n",
    "\n",
    "# print all the collected links after the loop finishes\n",
    "print(\"All links collected:\")\n",
    "for link in all_links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxscore_links = []\n",
    "\n",
    "# loop through each week link\n",
    "for link in all_links:\n",
    "    try:\n",
    "        print(f\"\\nNavigating to: {link}\")\n",
    "        driver.get(link)  # Open the page in the browser\n",
    "\n",
    "\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"fittPageContainer\")))\n",
    "\n",
    "\n",
    "        # extract the week number from the URL\n",
    "        week_number = link.split(\"/week/\")[1].split(\"/\")[0]  # Extracts the \"18\" from \"/week/18/\"\n",
    "\n",
    "        # extract boxscore links\n",
    "        boxscores = driver.find_elements(By.XPATH, '//a[contains(@href, \"/boxscore/\")]')\n",
    "\n",
    "        for item in boxscores:\n",
    "            boxscore = item.get_attribute('href')\n",
    "            if boxscore and '/boxscore/' in boxscore:\n",
    "                boxscore_links.append(boxscore)  # Append only the link (no dictionary)\n",
    "                print(f\"Found boxscore link: {boxscore}\")\n",
    "\n",
    "        if weeks_processed >= max_weeks_to_process:\n",
    "            break  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {link}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\nAll boxscore links collected:\")\n",
    "for link in boxscore_links:\n",
    "    game_ids = [link.split(\"gameId/\")[-1] for link in boxscore_links]\n",
    "    print(game_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.espn.com/nfl/boxscore/_/gameId/401671668 - Betting data not found.\n",
      "Skipping https://www.espn.com/nfl/boxscore/_/gameId/401671668 - Betting data not found.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "try:\n",
    "    for links1 in boxscore_links:\n",
    "\n",
    "        # open the page\n",
    "        driver.get(links1)\n",
    "\n",
    " \n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"GameInfo__BettingItem\")]'))\n",
    "            )\n",
    "        except:\n",
    "            print(f\"Skipping {links1} - Betting data not found.\")\n",
    "            continue  # Skip this game if betting data is missing\n",
    "\n",
    "        # getting the spread\n",
    "        spread = driver.find_elements(By.XPATH, '//div[contains(@class, \"GameInfo__BettingItem\")]')\n",
    "\n",
    "        spread_text = spread[0].text.strip()\n",
    "        over_text = spread[1].text.strip()\n",
    "\n",
    "\n",
    "        game_id = links1.split(\"gameId/\")[-1]\n",
    "\n",
    "  \n",
    "        game_insert_query = \"\"\"\n",
    "        INSERT INTO games (over_text, spread_text, game_id)\n",
    "        VALUES (%s, %s, %s)\n",
    "        \"\"\"\n",
    "        game_values = (over_text, spread_text, game_id)\n",
    "\n",
    "        cursor.execute(game_insert_query, game_values)  \n",
    "        db.commit()\n",
    "\n",
    "  \n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "finally:\n",
    " \n",
    "    cursor.close()\n",
    "    db.close()\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
