{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Set up WebDriver with headless mode\n",
    "options = webdriver.ChromeOptions()\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Navigate to the ESPN NFL scoreboard page\n",
    "driver.get(\"https://www.espn.com/nfl/scoreboard\")\n",
    "time.sleep(5)  # Allow page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize WebDriverWait\n",
    "wait = WebDriverWait(driver, 10)  # Define 'wait' here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriverWait\n",
    "wait = WebDriverWait(driver, 15)  # Define 'wait' here\n",
    "\n",
    "all_links = []\n",
    "\n",
    "while True:\n",
    "    # Use JavaScript to get all elements matching the selector\n",
    "    elements = driver.execute_script(\n",
    "        \"return [...document.querySelectorAll('.Arrow.flex.justify-center.items-center.Arrow--left')]\"\n",
    "    )\n",
    "\n",
    "    # Check if any elements were found\n",
    "    if not elements:\n",
    "        print(\"No elements found.\")\n",
    "        break\n",
    "\n",
    "    # Extract href attributes using JavaScript\n",
    "    week_js1 = driver.execute_script(\n",
    "        \"return [...document.querySelectorAll('div.Week.currentWeek div.Week__wrapper div.custom--week a')].map(e => e.href);\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Filter for only links containing '/season/2'\n",
    "    filtered_links = [link for link in week_js1 if \"/seasontype/2\" in link]\n",
    "    \n",
    "    # Add the extracted links to the list\n",
    "    # Convert to set to automatically remove duplicates\n",
    "    all_links = list(set(all_links + filtered_links))   \n",
    "\n",
    "    # Use JavaScript to check if the button is disabled\n",
    "    is_disabled = driver.execute_script(\n",
    "        \"\"\"\n",
    "        return document.querySelector('.Arrow.flex.justify-center.items-center.Arrow--left').classList.contains('disabled');\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # If the button is disabled, stop the loop\n",
    "    if is_disabled:\n",
    "        print(\"Reached the beginning of the carousel. Stopping.\")\n",
    "        break\n",
    "\n",
    "    # Click the first element in the list to go to the previous carousel page\n",
    "    elements[0].click()\n",
    "\n",
    "# Print all the collected links after the loop finishes\n",
    "print(\"All links collected:\")\n",
    "for link in all_links:\n",
    "    print(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List to store boxscore links\n",
    "boxscore_links = []\n",
    "\n",
    "# Loop through each week link\n",
    "for link in all_links:\n",
    "    try:\n",
    "        print(f\"\\nNavigating to: {link}\")\n",
    "        driver.get(link)  # Open the page in the browser\n",
    "\n",
    "        # Wait for the page to fully load\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"fittPageContainer\")))\n",
    "\n",
    "\n",
    "        # Extract the week number from the URL\n",
    "        week_number = link.split(\"/week/\")[1].split(\"/\")[0]  # Extracts the \"18\" from \"/week/18/\"\n",
    "\n",
    "        # Extract boxscore links\n",
    "        boxscores = driver.find_elements(By.XPATH, '//a[contains(@href, \"/boxscore/\")]')\n",
    "\n",
    "        for item in boxscores:\n",
    "            boxscore = item.get_attribute('href')\n",
    "            if boxscore and '/boxscore/' in boxscore:\n",
    "                boxscore_links.append(boxscore)  # Append only the link (no dictionary)\n",
    "                print(f\"Found boxscore link: {boxscore}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {link}: {e}\")\n",
    "\n",
    "# Print collected boxscore links\n",
    "print(\"\\nAll boxscore links collected:\")\n",
    "for link in boxscore_links:\n",
    "    game_ids = [link.split(\"gameId/\")[-1] for link in boxscore_links]\n",
    "    print(game_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQL Configuration\n",
    "DB_USER = \"root\"\n",
    "DB_PASSWORD = \"_Joseph344\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_NAME = \"NFL_Project2\"\n",
    "\n",
    "engine = create_engine(f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}\")\n",
    "\n",
    "csv_path = \"/Users/mattatchison/Documents/SQL_Projects/raw_all_games.csv\"\n",
    "\n",
    "def get_game_stats(game_id):\n",
    "    \"\"\"Fetches comprehensive game stats using ESPN APIs\"\"\"\n",
    "    summary_url = f\"https://site.api.espn.com/apis/site/v2/sports/football/nfl/summary?event={game_id}\"\n",
    "    scoreboard_url = f\"https://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard/{game_id}\"\n",
    "    \n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        summary_response = requests.get(summary_url, headers=headers, timeout=10)\n",
    "        scoreboard_response = requests.get(scoreboard_url, headers=headers, timeout=10)\n",
    "        \n",
    "        summary_response.raise_for_status()\n",
    "        scoreboard_response.raise_for_status()\n",
    "        \n",
    "        summary_data = summary_response.json()\n",
    "        scoreboard_data = scoreboard_response.json()\n",
    "        \n",
    "        # Extract metadata\n",
    "        week = summary_data.get(\"header\", {}).get(\"week\", \"na\")\n",
    "        season_type = scoreboard_data.get(\"season\", {}).get(\"slug\", \"na\")\n",
    "        game_date = scoreboard_data.get(\"date\", \"na\")\n",
    "        \n",
    "        # Get referees\n",
    "        refs = \", \".join([official.get(\"fullName\", \"na\") \n",
    "                         for official in summary_data.get(\"gameInfo\", {}).get(\"officials\", [])])\n",
    "        \n",
    "        scores = summary_data.get(\"header\", {}).get(\"competitions\", [{}])[0].get(\"competitors\", [])\n",
    "        for s in scores:\n",
    "            score = s.get(\"team\", \"na\")\n",
    "\n",
    "        all_stats = []\n",
    "\n",
    "        for team in summary_data.get(\"boxscore\", {}).get(\"teams\", []):\n",
    "            team_info = team.get(\"team\", {})\n",
    "            \n",
    "            team_data = {\n",
    "                \"game_id\": game_id,\n",
    "                \"score\": score, \n",
    "                \"team_name\": team_info.get(\"displayName\", \"Unknown\"),\n",
    "                \"team_abbreviation\": team_info.get(\"abbreviation\", \"na\"),\n",
    "                \"team_id\": team_info.get(\"id\", \"na\"),\n",
    "                \"referees\": refs,\n",
    "                \"home_away\": team.get(\"homeAway\", \"unknown\"),\n",
    "                \"game_date\": game_date,\n",
    "                \"week\": week,\n",
    "                \"season_type\": season_type\n",
    "                \n",
    "            }\n",
    "            \n",
    "            for stat in team.get(\"statistics\", []):\n",
    "                label = stat.get(\"name\", stat.get(\"label\", \"Unknown\"))\n",
    "                clean_label = label.lower().replace(\" \", \"_\")\n",
    "                team_data[clean_label] = stat.get(\"displayValue\", \"0\")\n",
    "            \n",
    "            all_stats.append(team_data)\n",
    "        \n",
    "        df = pd.DataFrame(all_stats)\n",
    "\n",
    "        if not df.empty:\n",
    "            # Save to MySQL\n",
    "            df.to_sql(\"team_stats\", con=engine, if_exists=\"append\", index=False)\n",
    "            print(f\"✅ Successfully saved game {game_id} (Week {week})\")\n",
    "\n",
    "            # Save to CSV (Append mode)\n",
    "            df.to_csv(csv_path, mode='a', header=not os.path.exists(csv_path), index=False)\n",
    "            print(f\"✅ Game {game_id} saved to CSV.\")\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"❌ HTTP Error for game {game_id}: {str(e)[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error for game {game_id}: {str(e)[:100]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Extract game IDs from boxscore_links (make sure `boxscore_links` exists)\n",
    "    game_ids = [link.split(\"gameId/\")[-1] for link in boxscore_links]   \n",
    "    \n",
    "    for game_id in game_ids:\n",
    "        print(f\"\\nProcessing Game ID: {game_id}\")\n",
    "        get_game_stats(game_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
